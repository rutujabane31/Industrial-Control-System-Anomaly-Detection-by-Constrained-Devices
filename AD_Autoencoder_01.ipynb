{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1da7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules#\n",
    "\n",
    "# numpy stack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc, precision_score, confusion_matrix, classification_report, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import binarize\n",
    "from autoencoder_BATADAL import load_AEED\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "# os and time utils\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9fa33eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autoencoder Classes#\n",
    "\n",
    "# classes\n",
    "class AutoEncoder(object):\n",
    "    \"\"\" Keras-based AutoEncoder (AE) class used for event detection.\n",
    "\n",
    "        Attributes:\n",
    "        params: dictionary with parameters defining the AE structure,\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\" Class constructor, stores parameters and initialize AE Keras model. \"\"\"\n",
    "        \n",
    "        # Default parameters values. If nI is not given, the code will crash later.\n",
    "        params = {\n",
    "            'nI': None,\n",
    "            'nH': 3,\n",
    "            'cf': 1,\n",
    "            'activation' : 'tanh',\n",
    "            'optimizer' : None,\n",
    "            'verbose' : 0\n",
    "            }\n",
    "\n",
    "        for key,item in kwargs.items():\n",
    "            params[key] = item\n",
    "        \n",
    "        self.params = params\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\" Creates Keras AE model.\n",
    "\n",
    "            The model has nI inputs, nH hidden layers in the encoder (and decoder)\n",
    "            and cf compression factor. The compression factor is the ratio between\n",
    "            the number of inputs and the innermost hidden layer which stands between\n",
    "            the encoder and the decoder. The size of the hidden layers between the \n",
    "            input (output) layer and the innermost layer decreases (increase) linearly\n",
    "            according to the cg.\n",
    "        \"\"\"\n",
    "        \n",
    "        # retrieve params\n",
    "        nI = self.params['nI'] # number of inputs\n",
    "        nH = self.params['nH'] # number of hidden layers in encoder (decoder)\n",
    "        cf = self.params['cf'] # compression factor\n",
    "        activation = self.params['activation'] # autoencoder activation function\n",
    "        optimizer = self.params['optimizer'] # Keras optimizer\n",
    "        verbose = self.params['verbose'] # echo on screen\n",
    "        \n",
    "        # get number/size of hidden layers for encoder and decoder\n",
    "        temp = np.linspace(nI,nI/cf,nH + 1).astype(int)\n",
    "        nH_enc = temp[1:]\n",
    "        nH_dec = temp[:-1][::-1]\n",
    "\n",
    "        # input layer placeholder\n",
    "        input_layer = Input(shape=(nI,))\n",
    "\n",
    "        # build encoder\n",
    "        for i, layer_size in enumerate(nH_enc):\n",
    "            if i == 0:\n",
    "                # first hidden layer\n",
    "                encoder = Dense(layer_size, activation=activation)(input_layer)\n",
    "            else:\n",
    "                # other hidden layers\n",
    "                encoder = Dense(layer_size, activation=activation)(encoder)\n",
    "\n",
    "        # build decoder\n",
    "        for i, layer_size in enumerate(nH_dec):\n",
    "            if i == 0:\n",
    "                # first hidden layer\n",
    "                decoder = Dense(layer_size, activation=activation)(encoder)\n",
    "            else:\n",
    "                # other hidden layers\n",
    "                decoder = Dense(layer_size, activation=activation)(decoder)\n",
    "\n",
    "        # create autoencoder\n",
    "        autoencoder = Model(input_layer, decoder)\n",
    "        if optimizer == None:\n",
    "            optimizer = optimizers.Adam(lr = 0.001)\n",
    "\n",
    "        # print autoencoder specs\n",
    "        if verbose > 0:\n",
    "            print('Created autoencoder with structure:');\n",
    "            print(', '.join('layer_{}: {}'.format(v, i) for v, i in enumerate(np.hstack([nI,nH_enc,nH_dec]))))\n",
    "\n",
    "        # compile and return model\n",
    "        autoencoder.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "        autoencoder.summary()\n",
    "        return autoencoder\n",
    "    \n",
    "    def build_predictor(self):\n",
    "        model = Sequential()\n",
    "        '''\n",
    "        model.add(LSTM(43,dropout_U = 0.2, dropout_W = 0.2, input_shape=(2,43)))# return_sequences=True, \n",
    "        #model.add(LSTM(43, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(43, activation = 'relu'))\n",
    "        '''\n",
    "        model.add(Conv1D(64, kernel_size=2, activation='relu', input_shape = (1,43), padding='same'))\n",
    "        model.add(MaxPooling1D(pool_size=1, strides=None))\n",
    "        model.add(Conv1D(128, 2, activation='relu', padding='same'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Conv1D(256, 2, activation='relu', padding='same'))\n",
    "        model.add(MaxPooling1D(pool_size=1))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.3, noise_shape=None, seed=13))\n",
    "        model.add(Dense(43, activation='relu'))     \n",
    "        \n",
    "        model.compile(loss='mean_squared_error', optimizer=  optimizers.Adam(lr = 0.001))\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def train(self, x, y, **train_params):\n",
    "        \"\"\" Train autoencoder,\n",
    "\n",
    "            x: inputs (inputs == targets, AE are self-supervised ANN).\n",
    "        \"\"\"        \n",
    "        if self.params['verbose']:\n",
    "            if self.ann == None:\n",
    "                print('Creating model.')\n",
    "                self.create_model()\n",
    "        self.ann.fit(x, y, **train_params)\n",
    "\n",
    "\n",
    "    def predict(self, x, test_params={}):\n",
    "        \"\"\" Yields reconstruction error for all inputs,\n",
    "\n",
    "            x: inputs.\n",
    "        \"\"\"\n",
    "        return self.ann.predict(x, **test_params)\n",
    "\n",
    "class AEED(AutoEncoder):\n",
    "    \"\"\" This class extends the AutoEncoder class to include event detection\n",
    "        functionalities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def difference(x):\n",
    "        return (x[-1] - x[0])**2\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\" Create the underlying Keras model. \"\"\"\n",
    "        self.ann = self.create_model()#self.build_predictor()#\n",
    "\n",
    "    def predict(self, x, y, **keras_params):\n",
    "        \"\"\" Predict with autoencoder. \"\"\"        \n",
    "        #preds = super(AEED, self).predict(x,keras_params)\n",
    "        #errors = pd.DataFrame((y-preds)**2)\n",
    "        #errors_1 = np.sqrt(np.mean((y - preds)**2))\n",
    "        #return preds, errors, errors_1   \n",
    "        preds = super(AEED, self).predict(x,keras_params)\n",
    "        errors = pd.DataFrame((y-preds)**2)\n",
    "        return preds, errors \n",
    "    #changed window from 1 to 3 below    \n",
    "    def detect(self, x, y, theta, window = 3, average=False, sys_theta = 0, **keras_params):\n",
    "        \"\"\" Detection performed based on (smoothed) reconstruction errors.\n",
    "\n",
    "            x = inputs,\n",
    "            theta = threshold, attack flagged if reconstruction error > threshold,\n",
    "            window = length of the smoothing window (default = 1 timestep, i.e. no smoothing),\n",
    "            average = boolean (default = False), if True the detection is performed\n",
    "                on the average reconstruction error across all outputs,\n",
    "            keras_params = parameters for the Keras-based AE prediction.\n",
    "        \"\"\"\n",
    "        #preds = super(AEED, self).predict(x,keras_params)\n",
    "        preds, temp = self.predict(x, y, **keras_params)\n",
    "        #temp = (x-preds)**2\n",
    "        if average:\n",
    "            #errors = temp.mean(axis=1).rolling(window=window).mean()             \n",
    "            #detection = errors > theta\n",
    "            # Calculate the rolling mean using np.convolve\n",
    "            window = np.ones(window) / window\n",
    "            errors = np.convolve(temp.mean(axis=1), window, mode='same')\n",
    "            detection = errors > theta\n",
    "        else:\n",
    "            #errors = temp.rolling(window=window).mean()\n",
    "            #detection = errors.apply(lambda x: x>np.max(theta.name, sys_theta)) \n",
    "            # Continue with the existing code for non-average case\n",
    "            errors = temp > theta\n",
    "            detection = np.any(errors, axis=1)\n",
    "            \n",
    "        return detection, errors\n",
    "\n",
    "    def save(self, filename, scaler, theta):\n",
    "        \"\"\" Save AEED modelself.\n",
    "\n",
    "            AEED parameters saved in a .json, while Keras model is stored in .h5 .\n",
    "        \"\"\"\n",
    "        # parameters\n",
    "        with open(filename+'.json', 'w') as fp:\n",
    "            json.dump(self.params, fp)\n",
    "        # keras model\n",
    "        self.ann.save(filename+'.h5')\n",
    "        with open(\"theta\", 'w') as f:\n",
    "            f.write(str(theta))\n",
    "        pickle.dump(scaler, open( \"scaler.p\", \"wb\" ))\n",
    "        # echo\n",
    "        print('Saved AEED parameters to {0}.\\nKeras model saved to {1}'.format(filename+'.json', filename+'.h5'))\n",
    "\n",
    "\n",
    "# functions\n",
    "def load_AEED(params_filename, model_filename):\n",
    "    \"\"\" Load stored AEED. \"\"\"\n",
    "    # load params and create AEED\n",
    "    with open(params_filename) as fd:\n",
    "        params = json.load(fd)\n",
    "    aeed = AEED(**params)\n",
    "\n",
    "    # load keras model\n",
    "    aeed.ann = load_model(model_filename)\n",
    "    return aeed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d8e0d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, window_size = 4):\n",
    "    \"\"\" \n",
    "    Creates the dataset composed by window_size samples of sensor readings and their relative label\n",
    "    \n",
    "    if windows size is 2, it returns a dataset composed [[[x-1, x][x]], [[x, x+1][x+1]], ...]\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset :  list\n",
    "        list of dataset samples\n",
    "    window_size : int\n",
    "        number of samples used for feeding the network.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np array\n",
    "        dataset samples organized in groups of windows_size\n",
    "    np array\n",
    "        target of model prediction\n",
    "    \"\"\"\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset) - window_size - 1):\n",
    "        a = dataset[i:(i + window_size + 1)] #remove +1 to turn into 1-step ahead prediction\n",
    "        data_X.append(a)\n",
    "        data_Y.append(dataset[i + window_size])\n",
    "    return(np.array(data_X), np.array(data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "41561ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data \n",
    "df_train_orig = pd.read_csv(\"train1.csv\", parse_dates=['Time'], dayfirst=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "42bdc069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dates and columns with sensor readings\n",
    "dates_train = df_train_orig['Time']\n",
    "sensor_cols = [col for col in df_train_orig.columns if col not in ['Time','BLANK1','BLANK2','BLANK3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6795da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203, 1, 81)\n",
      "(100, 1, 81)\n"
     ]
    }
   ],
   "source": [
    "# scale sensor data\n",
    "scaler = MinMaxScaler()\n",
    "X =scaler.fit_transform(df_train_orig[sensor_cols])\n",
    "# split into training and validation\n",
    "X1, X2, _, _  = train_test_split(X, X, test_size=0.33, random_state=42, shuffle=False)\n",
    "window = 0\n",
    "train_X, train_Y = create_dataset(X1, window) #to use also the current reading\n",
    "test_X, test_Y = create_dataset(X2, window)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5e1e4bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created autoencoder with structure:\n",
      "layer_0: 81, layer_1: 64, layer_2: 48, layer_3: 32, layer_4: 48, layer_5: 64, layer_6: 81\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 81)]              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 64)                5248      \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 48)                3120      \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 32)                1568      \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 48)                1584      \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 64)                3136      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 81)                5265      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,921\n",
      "Trainable params: 19,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Train Autoencoder#\n",
    "\n",
    "# define model parameters\n",
    "params = {\n",
    "    'nI' : X.shape[1],\n",
    "    'nh' : 3,\n",
    "    'cf' : 2.5,\n",
    "    'activation' : 'tanh',\n",
    "    'verbose' : 1,  \n",
    "}\n",
    "\n",
    "# create AutoEncoder for Event Detection (AEED)\n",
    "autoencoder = AEED(**params)\n",
    "autoencoder.initialize()\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# learning rate = 0.0001\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "#autoencoder.compile(optimizer=optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "63b656c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 - 1s - loss: 0.2241 - val_loss: 0.1576 - lr: 0.0010 - 1s/epoch - 152ms/step\n",
      "Epoch 2/500\n",
      "7/7 - 0s - loss: 0.1079 - val_loss: 0.1362 - lr: 0.0010 - 62ms/epoch - 9ms/step\n",
      "Epoch 3/500\n",
      "7/7 - 0s - loss: 0.0564 - val_loss: 0.1418 - lr: 0.0010 - 65ms/epoch - 9ms/step\n",
      "Epoch 4/500\n",
      "7/7 - 0s - loss: 0.0363 - val_loss: 0.1462 - lr: 5.0000e-04 - 51ms/epoch - 7ms/step\n",
      "Epoch 5/500\n",
      "7/7 - 0s - loss: 0.0302 - val_loss: 0.1470 - lr: 2.5000e-04 - 50ms/epoch - 7ms/step\n",
      "(203, 81) (203, 81)\n",
      "(100, 81) (100, 81)\n"
     ]
    }
   ],
   "source": [
    "# train models with early stopping and reduction of learning rate on plateau\n",
    "earlyStopping= EarlyStopping(monitor='val_loss', patience=3, verbose=0,  min_delta=1e-4, mode='auto')\n",
    "#lr_reduced = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=0, epsilon=1e-4, mode='min')\n",
    "lr_reduced = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=0, min_delta=1e-4, mode='min')\n",
    "   \n",
    "# initialize time\n",
    "start_time = time.time()\n",
    "\n",
    "# Remove the extra dimension from input data\n",
    "train_X = np.squeeze(train_X)\n",
    "test_X = np.squeeze(test_X)\n",
    "\n",
    "# train autoencoder\n",
    "autoencoder.train(train_X,train_Y,\n",
    "            epochs=500,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            callbacks = [earlyStopping, lr_reduced],\n",
    "            verbose = 2,\n",
    "            validation_data=(test_X, test_Y))\n",
    "\n",
    "print(train_X.shape, train_Y.shape)\n",
    "print(test_X.shape, test_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "80df65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Autoencoder#\n",
    "def compute_scores(Y,Yhat):\n",
    "    fpr, recall, _ = roc_curve(Y, Yhat)\n",
    "    return [accuracy_score(Y,Yhat),f1_score(Y,Yhat),precision_score(Y,Yhat),recall[1], fpr[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0daff370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of X3 and X4 (3129, 1, 81) (579, 1, 81)\n",
      "Shapes of Y3_target and Y4_target (3129, 81) (579, 81)\n",
      "Shapes of Y3 and Y4 (3130,) (580,)\n",
      "(3130,) (580,)\n"
     ]
    }
   ],
   "source": [
    "# Load the test datasets\n",
    "df_test_01 = pd.read_csv(\"test1.csv\")\n",
    "df_test_02 = pd.read_csv(\"test2.csv\")\n",
    "\n",
    "\n",
    "# scale datasets\n",
    "X3 = pd.DataFrame(index = df_test_01.index, columns = sensor_cols, \n",
    "                  data = scaler.transform(df_test_01[sensor_cols]))\n",
    "\n",
    "X4 = pd.DataFrame(index = df_test_02.index, columns = sensor_cols, \n",
    "                  data = scaler.transform(df_test_02[sensor_cols]))\n",
    "\n",
    "X3, Y3_target = create_dataset(X3.values, window) #to use also the current reading\n",
    "X4, Y4_target = create_dataset(X4.values, window)\n",
    "\n",
    "print(\"Shapes of X3 and X4\", X3.shape, X4.shape)\n",
    "print(\"Shapes of Y3_target and Y4_target\", Y3_target.shape, Y4_target.shape)\n",
    "# get targets\n",
    "#Y3 = df_test_01[sensor_cols]\n",
    "#Y4 = df_test_02[sensor_cols]\n",
    "len_01 = len(df_test_01)\n",
    "Y3 =  np.ones(len_01)\n",
    "len_02 = len(df_test_02)\n",
    "Y4 =  np.ones(len_02)\n",
    "print(\"Shapes of Y3 and Y4\", Y3.shape, Y4.shape)\n",
    "print(Y3.shape, Y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0cffa153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "98/98 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Shapes of Yhat3 and Yhat4 (3129,) (579,)\n",
      "Shapes of Yhat3 and Yhat4 [False False False ...  True  True  True] [False False False False False  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "False True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X3 = X3.reshape(X3.shape[0], X3.shape[2])  # reshape X3 to (8347, 81)\n",
    "X4 = X4.reshape(X4.shape[0], X4.shape[2])  # reshape X4 to (8347, 81)\n",
    "\n",
    "# perform detection\n",
    "\n",
    "# get validation reconstruction errors\n",
    "_, validation_errors = autoencoder.predict(test_X, test_Y)\n",
    "#print(validation_errors)\n",
    "\n",
    "# plot distribution of average validation reconstruction errors \n",
    "f, ax = plt.subplots(1, figsize = (8,4))\n",
    "sns.boxplot(validation_errors.mean(axis=1), ax=ax)\n",
    "ax.set_xlim([0,0.005])\n",
    "ax.set_title('Boxplot of average validation reconstruction errors')\n",
    "\n",
    "\n",
    "# set treshold as quantile of average reconstruction error\n",
    "theta = validation_errors.mean(axis = 1).quantile(0.995)\n",
    "\n",
    "Yhat3, _ = autoencoder.detect(X3, Y3_target, theta = theta , window = 3, average=True)\n",
    "Yhat4, _ = autoencoder.detect(X4, Y4_target, theta = theta, window = 3, average=True)\n",
    "print(\"Shapes of Yhat3 and Yhat4\", Yhat3.shape, Yhat4.shape)\n",
    "print(\"Shapes of Yhat3 and Yhat4\", Yhat3, Yhat4)\n",
    "print(Yhat3.min(), Yhat3.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15354ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "43d6f64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "                 accuracy  f1_score precision    recall  fpr\n",
      "test dataset 01  0.994247  0.997115         1  0.994247  NaN\n",
      "test dataset 02  0.991364  0.995663         1  0.991364  NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:803: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\"No negative samples in y_true, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy     0.992806\n",
       "f1_score     0.996389\n",
       "precision    1.000000\n",
       "recall       0.992806\n",
       "fpr               NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yhat3_1 = Yhat3*1\n",
    "Yhat4_1 = Yhat4*1\n",
    "results = pd.DataFrame(index = ['test dataset 01','test dataset 02'], \n",
    "                       columns = ['accuracy','f1_score','precision','recall','fpr'])\n",
    "results.loc['test dataset 01'] = compute_scores(Y3[:-1],Yhat3_1)\n",
    "results.loc['test dataset 02'] = compute_scores(Y4[:-1],Yhat4_1)\n",
    "\n",
    "\n",
    "print('Results:\\n')\n",
    "print(results)\n",
    "results.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c6ad6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a0acc23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Average prediction time per batch: 0.0491\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Average prediction time per batch for X4: 0.0492\n"
     ]
    }
   ],
   "source": [
    "# Calculate prediction time per batch\n",
    "batch_size = 32\n",
    "prediction_times = []\n",
    "\n",
    "for i in range(0, len(X3), batch_size):\n",
    "    start_time_batch = time.time()\n",
    "\n",
    "    X3_batch = X3[i:i + batch_size]\n",
    "    Y3_batch = Y3_target[i:i + batch_size]\n",
    "\n",
    "    _, _ = autoencoder.detect(X3_batch, Y3_batch, theta=theta, window=3, average=True)\n",
    "\n",
    "    end_time_batch = time.time()\n",
    "    prediction_time_batch = end_time_batch - start_time_batch\n",
    "    prediction_times.append(prediction_time_batch)\n",
    "\n",
    "average_prediction_time_per_batch = sum(prediction_times) / len(prediction_times)\n",
    "average_prediction_time_per_batch = round(average_prediction_time_per_batch, 4)  # Round to 4 decimal places\n",
    "print(\"Average prediction time per batch:\", average_prediction_time_per_batch)\n",
    "\n",
    "# Calculate prediction time per batch for X4\n",
    "prediction_times_X4 = []\n",
    "\n",
    "for i in range(0, len(X4), batch_size):\n",
    "    start_time_batch = time.time()\n",
    "\n",
    "    X4_batch = X4[i:i + batch_size]\n",
    "    Y4_batch = Y4_target[i:i + batch_size]\n",
    "\n",
    "    _, _ = autoencoder.detect(X4_batch, Y4_batch, theta=theta, window=3, average=True)\n",
    "\n",
    "    end_time_batch = time.time()\n",
    "    prediction_time_batch = end_time_batch - start_time_batch\n",
    "    prediction_times_X4.append(prediction_time_batch)\n",
    "\n",
    "average_prediction_time_per_batch_X4 = sum(prediction_times_X4) / len(prediction_times_X4)\n",
    "average_prediction_time_per_batch_X4 = round(average_prediction_time_per_batch_X4, 4)  # Round to 4 decimal places\n",
    "print(\"Average prediction time per batch for X4:\", average_prediction_time_per_batch_X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28493c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
